---
title: "Step_1_Collection"
author: "DG"
date: "July 6, 2023"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
editor_options: 
  markdown: 
    wrap: 70
---

```{=html}
<style type="text/css">
  body{
  font-size: 13pt;
}
</style>
```
This step is mostly debugging and will not be interesting to anyone
who is not analyzing their own data but maybe look at the pretty
latter plots. A lot of the debugging is necessary because I added
decks in weird ways, Anki is being constantly developed, and I use
many addons. If you are running this on your own data you should check
the output of each and every code section carefully. Look for label
CHANGEME, which for the following notebook is mostly errors.

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
options(max.print=200) 
```

## LOAD AND CLEAN DATA

Load Anki's sqlite database and turn it into several R tables.

```{r Load Ankis SQlite DB}


require(DBI)
#CHANGEME
COLLECTION_PATH <- "collection2025-1-15.anki2"
connection <- dbConnect(RSQLite::SQLite(), dbname=COLLECTION_PATH)
rev <- dbGetQuery(connection,'SELECT * FROM revlog')

#?dbGetQuery
each.table <- dbListTables(connection)
al<-list(each.table)
for (i in each.table) {
  try({
  eh<-dbGetQuery(connection,(paste0('SELECT * FROM ',i)))
  al[[which(each.table==i)]]<-NA
  names(al)[[which(each.table==i)]] <- i
  al[[which(each.table==i)]]<-eh
  })
} 
#names(al)
lapply(al, dim)
dbDisconnect(connection)
{
print("following tables did not load properly")
print(each.table[!(each.table %in%  names(al))])
}
note<-al$notes
cards<-al$cards
dek<-al$decks
fields<-al$fields
#names(dek)
#head(dek$id)
notetypes<-al$notetypes
templates<-al$templates

names(note)
View(al$deck_config)
```

```{r load tidyverse silently, include=FALSE}
require(tidyverse, quietly = T)
require(ggraph, quietly = T)
require(tidygraph, quietly = T)
```

```{r small helper functions}
#various summaries of a single variable
summ <- function(inc, by=.05){
  try({
  inc<-as.numeric(inc)
    print(str(inc))
    print(summary(inc))
  worth<-table(inc)
  if(length(worth)<10) print(worth)
  hist(inc,breaks=200)
  print(quantile(inc,seq(.000,.999999,length.out=(1/by +2))))
  })
}

#shorter table summary of a single  variable
st <- function(tbl) {
  tbp <- sort(table(tbl),decreasing=T)
  print(tbp[1:min(10,length(tbp))])
}

  milli_to_date <- function(mili) as.Date((mili)/(24*60*60*1000), origin = "1970-01-01")
    milli_to_days <- function(mili) round((mili)/(24*60*60*1000),digits=3)
     secs_to_date <- function(mili) as.Date((mili)/(24*60*60), origin = "1970-01-01")
```

Basic history plots and info. Maybe reveal bug.

```{r plot simple use history}
 #milli_to_date <- function(mili) as.Date((mili)/(24*60*60*1000), origin = "1970-01-01")
reviews.per.card <- sort(table(rev$cid),decreasing = T)
hist(reviews.per.card,breaks = 60)
cards.reviewed.each.month <- milli_to_date(rev$id)
hist(cards.reviewed.each.month,breaks = 60)

{
print("reviews")
print(length(rev$cid))
print("cards reviewed at least once")
print(length(unique(rev$cid)))
print(paste("when was last review:",milli_to_date(max(rev$id,na.rm=T)))) 
print(paste("when was first review:",milli_to_date(min(rev$id,na.rm=T))))
}
```

Columns probably for syncing. Removing most. Plot of when cards
modified.

```{r investigate columns for mod ification time}
{
hist(secs_to_date(cards$mod),breaks = 100)
print("cards$mod") #actualy keep this for reasons
st(secs_to_date(cards$mod))


#cards$mod <- NULL
names(cards)[names(cards)=="mod"] <- "mod_secs_cards"

  
print("note$mod")#this not useful; again related to other users?
st(secs_to_date(note$mod))
#hist(secs_to_date(note$mod),breaks = 100)
#note$mod <- NULL
#when last modified double check this is not useful in any way?
note$flds[order(-note$mod)]
names(note)[names(note)=="mod"] <- "mod_note"
note$mod_note <- NULL 

print("what is mtime_secs?")
print("dek$mtime_secs") #idk
st(secs_to_date(dek$mtime_secs))
#hist(secs_to_date(dek$mtime_secs),breaks=100)
dek$mtime_secs <- NULL 

print("templates$mtime_secs") #idk
st(secs_to_date(templates$mtime_secs))
#hist(secs_to_date(templates$mtime_secs),breaks=100)
templates$mtime_secs <- NULL 

print("notetypes$mtime_secs") #idk
st(secs_to_date(notetypes$mtime_secs))
#hist(secs_to_date(notetypes$mtime_secs),breaks = 100)
notetypes$mtime_secs <- NULL 
}
```

remove meaningless variables

```{r document all columns and remove meaningless ones}
{


#names(notetypes)[names(notetypes)=="mtime_secs"] <- "mtime_secs_notetypes"


print("cards$data")
st(cards$data)
cards$data<-NULL#unused

print("note$data")
st(note$data)
note$data<- NULL

print("note$flags")
st(note$flags)
note$flags<- NULL#empty

print("note$guid") #globally unique ID
st(note$guid)
note$guid<- NULL #man idk

print("note$id just to check") #globally unique ID
st(note$id)

print("note$csum") #checksum to avoid duplicates but useless for me bc only first 8 chars and there are plenty of cards starting with 'working memory'
#st(note$csum)
# note %>%
#   group_by(csum) %>%
#   mutate(count = n()) %>%
#   ungroup() %>%
#   arrange(sfld)  %>%
#   arrange(-count)
note$csum<- NULL #man idk


}
```

Its recommended to sync your collection before using this notebook.
Remove column used for syncing. USN -1 means needs to be pushed.

```{r remove column sync}
{

print("cards$usn")
st(cards$usn)
cards$usn <- NULL#for syncing 

print("note$usn")
st(note$usn)
note$usn <- NULL

print("dek$usn")
st(dek$usn)
dek$usn <- NULL

print("notetypes$usn")
st(notetypes$usn)
notetypes$usn <- NULL

print("templates$usn")
st(templates$usn)
templates$usn <- NULL

print("rev$usn")
st(rev$usn)
rev$usn <- NULL
}
```

rename columns

```{r rename some variables}
#this part may better belong in 'merge all' block
names(note)[names(note)=="id"] <- "nid"
names(note)[names(note)=="mid"] <- "ntid"
names(note)[names(note)=="sfld"] <- "cue.text.simple"
names(note)[names(note)=="flds"] <- "card.txt"
names(note)[names(note)=="tags"] <- "tags.note"

names(cards)[names(cards)=="id"] <- "cid"
names(dek)[names(dek)=="id"] <- "did"
names(dek)[names(dek)=="name"] <- "dek.nam" 

```

Filtered deck ids replaced with original deck ids. As main meaning of
'deck' is similar subject not schedule this is obviously right. Not
sure about due though. Better filtered decks not have cards in them
when running this notebook i think.

```{r filtered decks maybe important}
{
 updd <- cards$odid != 0
  print(paste("number cards in filtered decks", sum(updd)))
 
print("cards$odid")
st((cards$odid))

#cards$odid<-NULL #original deck id before card was moved to filtered deck!!!!!!!
#this is important for deck subject matter so did will be replaced wherever odid is not 0

# cards[updd,]
# todid <- unique(cards$odid[updd])
# tdid <- unique(cards$did[updd])
# summary(cards$did %in% tdid)
# summary(cards$did %in% todid)
# cards[cards$due<0,]
# summary(cards$due)
# summary(cards$odue)

print("cards$odue")
st((cards$odue)) 
#cards$due get weirds (less than 0) when in filtered deck so due reverted as well
if(sum(updd)>0) {
  #print("never tested TODO WARNING")
  cards$did[updd] <- cards$odid[updd]
  cards$due[updd] <- cards$odue[updd]
}
cards$odid<-NULL
cards$odue<-NULL
}
```

Cleaning text function. Clean deck names as well as card text.
CHANGEME if bug.

```{r clean deck names}
#travels around this notebook because takes so long
{
require(stringr, quietly = T)
clean_strings <- function(ws,remove.digits=T){
ws <- gsub(pattern = '\037'," -- ",ws,fixed = T)
ws <- gsub(pattern = '<img src='," AN_IMAGE_HERE<  ",ws,fixed = T)
ws <- gsub(pattern = '<.+?>'," ",ws,fixed = F)
ws <- gsub(pattern = '[sound:'," SOUND_HERE[",ws,fixed = T)
ws <- gsub(pattern = '\\[.+?\\]'," ",ws,fixed = F)
ws <- gsub(pattern = '{{c'," ",ws,fixed = T)
ws <- gsub(pattern = '::',":",ws,fixed = T)
ws <- gsub(pattern = '}}'," ",ws,fixed = T)
if(remove.digits){
  ws <- gsub(pattern = '[[:digit:]][[:digit:]][[:digit:]]+'," % ",ws,fixed = F)
}
ws <- gsub(pattern = 'nbsp'," ",ws,fixed = T)
ws <- gsub(pattern = '/n'," ",ws,fixed = T)
ws <- str_squish(ws)
ws <- str_squish(ws)
#ws <- str_squish(ws)
#ws <- gsub(pattern = '-- -- ',"-- ",ws,fixed = T)
#ws <- gsub(pattern = '-- -- ',"-- ",ws,fixed = T)
#must not remove fields even if they are not filled
} 

if(T){
deck_count <- (unique(dek$dek.nam))

dek$dek.nam.old <- dek$dek.nam
dek$dek.nam <- sapply(dek$dek.nam,clean_strings,remove.digits=F)
 
deck.names.redun <- length(deck_count) - length(unique(dek$dek.nam))
print(paste0("count of deck names ",deck.names.redun," made identical by string cleaning in dek"))
 
if(deck.names.redun>0) {
  print("CHANGEME If any deck names became identical to other deck names because of cleaning this will cause errors. Please edit the names of the following decks in anki and run notebook on your new collection file.")
  dek %>% 
    group_by(dek.nam) %>%
    summarize(n_dids=length(unique(did))) %>%
    filter(n_dids>1)
  stop()
}
}

if(T){ 
card_count <- length(unique(note$card.txt))

note$card.txt.old <- note$card.txt
note$card.txt <- sapply(note$card.txt,clean_strings,remove.digits=F)
  
card.text.redun <- card_count - length(unique(note$card.txt))
print(paste0("count of card.txt ",card.text.redun," made identical by string cleaning in note table"))
if(card.text.redun>0) {
  print("This is not terribly important but consider editing the following cards. Shows the importance of using olds when comparing cards")
  note %>% 
    group_by(card.txt) %>%
    summarize(n_old_txt = length(unique(card.txt.old)),
              one.card.txt.old = first(card.txt.old),
              two.card.txt.old = last(card.txt.old)
              ) %>%
    filter(n_old_txt>1) %>%
    arrange(-n_old_txt)
  
    #note that cards that were duplicates without cleaning will be checked for later
}
} 
}
```

## MERGE many different tables into 2

```{r note and card ids are not useful}
hist(milli_to_date(cards$cid),100)
hist(milli_to_date(note$nid),100)
```

All id are the timestamp in miliseconds of objects creation or
occurence. Card and note ids are universal based on ankiweb (? i never
synced) and so are not meaningful variables. This is good because cid
can now be used as purely join key. The two timestamps are very
similar. Card is the 'side' of a note, ex. one specific empty spot in
a cloze deletion phrase. "The number of new cards you have added" in
anki's stats window, uses nid or cid. According to it, I started my
collection 12 years ago, which is not even close to true. For
determining when something was added to collection I will use DID
(deck). When card was reviewed is called id in rev data frame.

Merge all useful info into a single object (sheet). Bug checks too.
really two; crd and rev.

```{r merge most data into single structure}
{

print(paste("percent card's note id in note's ids:",
            round(sum(cards$nid %in% note$nid)/length(cards$nid),3)))
print(paste("percent note's note id in card's ids:",
            round(sum(note$nid %in% cards$nid)/length(note$nid),3)))
cards<-merge(cards,note,all.x = T,all.y=F)
print(paste("percent card's deck id in deck's ids :",
            round(sum(cards$did %in% dek$did)/length(cards$did),3)))
print(paste("percent deck's deck id in card's ids :",
            round(sum(dek$did %in% cards$did)/length(dek$did),3)))
print("umm decks without cards?? deleted decks?")
crd<-merge(cards,dek[,c("did","dek.nam","dek.nam.old")],all.x = T,all.y=F)

#names(crd)
print(paste("percent review's card id in card's ids :",
            round(sum(rev$cid %in% cards$cid)/length(rev$cid),3)))
print("this is probably percent 1 - percent of cards deleted")
print(paste("percent cards's card id in review's ids :",
            round(sum(cards$cid %in% rev$cid)/length(cards$cid),3)))
print(paste("calculated by ",round(sum(cards$cid %in% rev$cid),3)," / ", round(length(cards$cid),3)))
print("this is just percent of cards ever reviewed and not a bug")

rev2<-merge(rev,crd[,c("cid","did","nid","card.txt","card.txt.old","dek.nam")],all.x = T,all.y=F,by="cid")
}
stopifnot(
  dim(crd)[1]==dim(cards)[1],
  dim(rev)[1]==dim(rev2)[1])

rev<-rev2
rm(rev2);
#Note to self: some cards are removed later because of terrible deck id.
```

Anki's own statistics say cards unseen are .244 percent or (56832 -
42990) 13842 / 56832 . It counts notes not cards. See Section
TIMESTAMP.

Convert out of int64 because R works more reliably with numeric.

```{r convert revs ids out of int64}
rev <- rev[order(rev$id),]
least_rev_id <- min(rev$id)
rev$idn <- as.numeric(rev$id)

{
print(paste("converted ids same as unconverted:",all(rev$id == rev$idn)))
print(paste("conversion to numeric unsuccesfull:",sum((rev$id - rev$idn) != 0)))
print(paste("when was last review:",milli_to_date(max(rev$idn,na.rm=T)))) 
}

rev$id  <- as.numeric(rev$id) 

rev$idn <- NULL
rev$cid <- as.numeric(rev$cid)
rev$did <- as.numeric(rev$did)
rev$nid <- as.numeric(rev$nid)
#summary(rev)
#str(rev)

crd$cid <- as.numeric(crd$cid)
crd$did <- as.numeric(crd$did)
crd$nid <- as.numeric(crd$nid)
crd$ntid <- as.numeric(crd$ntid)

```




## CLEAN more

Later on reps column in crd will not agree with reviews because many
reviews will have been deleted for error correction. If u see any deck
names just bellow, that means reviews and reps already disagree which
is a bug.

```{r what is reps really}
crd$in_rev <- (crd$cid) %in% rev$cid
if( !all((crd$reps>0) == crd$in_rev)){
summary(crd$reps>0)
summary(crd$in_rev)

summary(reviews.lost <- (crd$reps>0 & !crd$in_rev))
unique(crd$dek.nam[reviews.lost])
summary(reps.reset <- (!crd$reps & crd$in_rev))
unique(crd$dek.nam[reps.reset])
}
```

Remove rows with nas. In my case these were almost certainly reviews
of deleted cards.

```{r remove rows with nas}
{
  #require(naniar)
require(visdat, quietly = T)

rowrm <- apply(rev,1,function(x) any(is.na(x)))

print(paste("number of rows with na which will be removed",sum(rowrm)))
print("this is likely because of missing ids during join")

print(vis_miss(rev[rowrm,], cluster = TRUE))
rev <- rev[!rowrm,]
}
```

```{r remove rows with nas from crd table}
rowrm <- apply(crd,1,function(x) any(is.na(x)))
if(sum(rowrm)>1){
print(paste("Same as above but cards table. number of rows with na which will be removed",sum(rowrm)))
print("this is likely because of missing ids during join")

print(vis_miss(crd[rowrm,], cluster = TRUE))
crd <- crd[!rowrm,]
}
```

Find duplicate card text and card ids from Reviews. Up to user to do
something about it. Anki has duplicates finder but its for power
users.

```{r duplicate card text}

#crd <- crd[order(crd$nid),]
#crd$ohno <- duplicated(crd$card.txt.old) + duplicated(crd$card.txt.old, fromLast = TRUE)
#print(crd[crd$ohno>0,])

rev<-rev[order(rev$card.txt.old),]
list.of.rev<-rev %>% 
  group_by(card.txt.old) %>%
   summarise(dif.nid=n_distinct(nid),
             deck=first(dek.nam),deck2=last(dek.nam)) %>%
  filter(dif.nid>1) 
if(dim(list.of.rev)[1]>0){
print("Duplicate Card Text")
print(unique(c(list.of.rev$deck,list.of.rev$deck2)))
print((list.of.rev[,c(1)]) )
}
 
list.of.rev.idd<-rev %>% 
  group_by(nid) %>%
   summarise(dif.nid=n_distinct(card.txt.old),
             deck=first(dek.nam),deck2=last(dek.nam)) %>%
  filter(dif.nid>1)  
if(dim(list.of.rev.idd)[1]>0){
print("Multiple IDs per cardtext")
print(unique(c(list.of.rev.idd$deck,list.of.rev.idd$deck2)))
print((list.of.rev.idd[,c(1)]) )
}


```

Duplicates card text with different note ids and in different decks.

```{r more duplicate cards}

dup <- crd %>%
  group_by(card.txt) %>%
  summarize(nid.count=length(unique(nid)),
        did.count=length(unique(did)),
        dek.nam=first(dek.nam),
        deknamtwo=last(dek.nam)) %>%
  filter((nid.count)>1) %>%
  filter((did.count)>1) %>%
  ungroup() %>%
  arrange(dek.nam) %>%
  arrange(-nid.count)
  

# to.pretty <- sort(table(dup$deck),decreasing=T)
# as.data.frame(list(dek=names(to.pretty),count=to.pretty))
#as_tibble(as.data.frame(sort(table(dup$dek.nam),decreasing=T)))
dup[,c("card.txt","dek.nam","nid.count")]
```

Duplicate card text with different note ids but in the same decks.

```{r what makes duplicate cards}

dup <- crd %>%
  group_by(card.txt) %>%
  summarize(nid.count=length(unique(nid)),
        did.count=length(unique(did)),
        dek.nam=first(dek.nam),
        deknamtwo=last(dek.nam) ) %>%
  filter((nid.count)>1) %>%
  filter((did.count)==1) %>%
  ungroup() %>%
  arrange(dek.nam) %>%
  arrange(-nid.count) 

dup[,c("card.txt","dek.nam","nid.count")]
```

Duplicate decks! if greater than 90% duplicated, recommend deleting
one of them anyway. On the other hand making duplicate decks is an
quick way to manipulate the Subject detection algorithm.

```{r Duplicat decks}
 crd %>%
  group_by(card.txt.old) %>%
  mutate(nid.count=length(unique(nid)),
        did.count=length(unique(did)) ) %>%
  ungroup() %>%
  group_by(dek.nam) %>%
  summarize(
    percent.elsewhere = (sum(did.count>1) / n())
  ) %>%
  ungroup() %>%
  arrange(-percent.elsewhere)%>%
  filter(percent.elsewhere>.33)

```

Quick check.

```{r check test}
rev <- rev[order(rev$id),]
{
# print('all id are the timestamp in miliseconds of objects creation or occurence')
 print(paste("when was last review:",milli_to_date(max(rev$id,na.rm=T)))) 
 print(paste("which rev ids na:",which(is.na(rev$id))))
 print(paste("which rev ids are duplicated:",which(duplicated(rev$id))))
 print(paste("any timings reverse order or lags become zero:",which(diff(rev$id)<=0)))
# print("no more NAs and no more int64s either")
#summary(rev)
#str(rev)
}
```

Quick check of card table.

```{r quick check of card table}
{
print("following regards card data table")
print(paste("count of unique card text",length(unique(crd$card.txt.old))))
print(paste("count of unique note ids",length(unique(crd$nid))))
print("difference between the above two values is number of duplicate cards")
print(paste("count of unique card ids",length(unique(crd$cid))))
print(paste("dimensions of card object",paste(dim(crd),collapse = " ")))
}
```

## TIMESTAMP MISSALIGNMENT

```{r reviews and cards per deck}
#reviews and cards per deck into Reviews 
rev <- rev %>%
  group_by(dek.nam) %>%
   mutate(cards.in.dek=n_distinct(cid),
             revs.in.dek=n())%>%
  arrange(id)%>%
  ungroup()
```

Set to about median ids that are way too early to be timestamps.

```{r fix non timestamp ids}
{
print(paste0("count of IDs too low to be timestamps in reveiws. rev ", sum(rev$id<10000)," card ", sum(rev$cid<10000), " note ",sum(rev$nid<10000), " deck ", sum(rev$did<10000)))

print(paste0("count of IDs too low to be timestamps in crd. card ", sum(crd$cid<10000), " note ",sum(crd$nid<10000), " deck ", sum(crd$did<10000)))

if(sum(rev$id<10000) > 1) warning("rev id timestamps that are too low removed later")


if(any(crd$did<10000)){
  print(("names of weird decks the Id of which is not timestamp"))
  print((unique(crd$dek.nam[crd$did<10000])))
  print(paste("number of reviews in weird decks",sum(rev$did<10000)))
  print(paste("first,last rev in those decks",
              milli_to_date(rev$id[rev$did<10000][1]),
              milli_to_date(rev$id[rev$did<10000][sum(rev$did<10000)])))
  if(F)#sum(rev$did<10000) < dim(rev)[1]*.005)
    {
  print("looks not too bad in this case so deck will be deleted")
  #print(unique(rev$card.txt.old[rev$did==1]))
  rev<-rev[rev$did>10000,]
  crd<-crd[crd$did>10000,]
  }
  else{
    print("deck id stamp will be set near to median")
    medek <- median(sort((crd$did))) - 300000000
    while(any(crd$did<10000)){
    while((medek %in% crd$did) ||
          (medek %in% crd$nid) ||
          (medek %in% rev$id) || 
          (medek %in% crd$cid)) {
      medek<-medek-1
    }
    rev$did[rev$did==min(crd$did)]<-medek
    crd$did[crd$did==min(crd$did)]<-medek
    }
  }
}
}
```

```{r fix non timestamp ids continued}
if(any(crd$nid<10000)){
  print(("names of weird decks the nId of which is not timestamp"))
  print((unique(crd$dek.nam[crd$nid<10000])))
  print(paste("number of reviews of weird notes",sum(rev$nid<10000)))
  print(paste("first,last rev of those notes",
              milli_to_date(rev$id[rev$nid<10000][1]),
              milli_to_date(rev$id[rev$nid<10000][sum(rev$nid<10000)])))
  if(F)#sum(rev$nid<10000) < dim(rev)[1]*.005)
    {
  print("looks not too bad in this case so notes will be deleted")
  #print(unique(rev$card.txt.old[rev$nid==1]))
  rev<-rev[rev$nid>10000,]
  crd<-crd[crd$nid>10000,]
  }
  else{
    print("note id stamp will be set near to median")
    medek <- median(sort((crd$nid)))
    while(any(crd$nid<10000)){
    while((medek %in% crd$did) ||
          (medek %in% crd$nid) ||
          (medek %in% rev$id) || 
          (medek %in% crd$cid)) {
      medek<-medek+1
    }
    rev$nid[rev$nid==min(crd$nid)]<-medek
    crd$nid[crd$nid==min(crd$nid)]<-medek
    }
  }
}

if(any(crd$cid<10000)){
  print(("names of weird decks the cid of which is not timestamp"))
  print((unique(crd$dek.nam[crd$cid<10000])))
  print(paste("number of reviews of weird cards",sum(rev$cid<10000)))
  print(paste("first,last rev of those cards",
              milli_to_date(rev$id[rev$cid<10000][1]),
              milli_to_date(rev$id[rev$cid<10000][sum(rev$cid<10000)])))
  if(F)#sum(rev$nid<10000) < dim(rev)[1]*.005)
    {
  print("looks not too bad in this case so notes will be deleted")
  #print(unique(rev$card.txt.old[rev$nid==1]))
  rev<-rev[rev$cid>10000,]
  crd<-crd[crd$cid>10000,]
  }
  else{
    print("card id stamp will be set near to median")
    medek <- median(sort((crd$cid)))
    while(any(crd$cid<10000)){
    while((medek %in% crd$did) ||
          (medek %in% crd$nid) ||
          (medek %in% rev$id) || 
          (medek %in% crd$cid)) {
      medek<-medek+1
    }
    rev$cid[rev$cid==min(crd$cid)]<-medek
    crd$cid[crd$cid==min(crd$cid)]<-medek
    }
  }
}


```

```{r quickcheck}
{
  print(paste0("count of IDs too low to be timestamps in reveiws. rev ", sum(rev$id<10000)," card ", sum(rev$cid<10000), " note ",sum(rev$nid<10000), " deck ", sum(rev$did<10000)))

print(paste0("count of IDs too low to be timestamps in crd. card ", sum(crd$cid<10000), " note ",sum(crd$nid<10000), " deck ", sum(crd$did<10000)))


print(paste("total revs left:",dim(rev)[1]))
if(sum(rev$cid>rev$id)>0) print(paste("number reviews with card created after review somehow ",sum(rev$cid>rev$id)))
#if(sum(rev$did>(rev$cid))>0) print(paste("number reviews with deck created after card somehow",sum(rev$did>(rev$cid-10))))
#as established cid is not relevant
  
rev$time.missalign=rev$did>rev$id
if(sum(rev$time.missalign)>0) print(paste("number reviews with deck created after review somehow",sum(rev$time.missalign)))
}
```

In my database most reviews before deck creation were caused by an
Anki upgrade changed them. TODO (likely problematic) They should be
fixed by undoing the change but currently just deleted. Also some of
the decks were installed in a weird way and kept the makers review
history. These reviews will be deleted. One case was probably caused
by editing a card and should be ignored. Could moving cards between
decks cause this problem too?

Following code removes reviews made before the deck timestamp and
reviews made before a certain date. Deck ids will be increased.

CHANGEME U may want to change which of the 4 removal methods activate
by altering the Ts and Fs. Remove specific decks. Remove reviews
before their deck's timestamp. Remove reviews before a certain time
set in 'first_time_used_anki'. Change deck id to after anki is used
first time.

```{r find and remove problem reviews and decks}
{
#remove some specific decks 
if(F){
library(stringr)
rev<-rev[!str_detect(rev$dek.nam,
              stringr::fixed("ProgramingAdvancedWide")),]
rev<-rev[!str_detect(rev$dek.nam,
              stringr::fixed("Paper Recursive Feedback")),]

crd<-crd[!str_detect(crd$dek.nam,
              stringr::fixed("ProgramingAdvancedWide")),]

rev %>%
  arrange(id) %>%
  group_by(dek.nam) %>%
  arrange(id) %>%
   summarise(cards.in.dek=n_distinct(cid),
             revs.in.dek=n())%>%
  arrange(desc(cards.in.dek))
}
#remove reviews before their decks
if(T){
  rev$time.missalign=rev$did>rev$id
  print(" ")
print(paste("number reviews with deck created after review to be deleted", sum(rev$time.missalign)))
print(as_tibble(as.data.frame(table(rev[rev$time.missalign,]$dek.nam))))
  rev <- rev[!rev$time.missalign,]
}
#remove reviews before a certain time
if(T){
  first_time_used_anki <- 1.548563e+12
  to_fix <- rev$id<first_time_used_anki
  print(paste("number reviews before ",milli_to_date(first_time_used_anki)," to be deleted ",  sum(to_fix)))
  print(as_tibble(as.data.frame(table(rev[to_fix,]$dek.nam))))
rev <- rev[!to_fix,] 
}

#move deck id to better a point in time 
if(T){
  deks_to_fix <- unique(crd[crd$did<first_time_used_anki,]$dek.nam)
  print(" ")
  print("deck id timestamps updated to about anki first use ")
  print(deks_to_fix[1:5])
  #real_first_use <- (min(rev$id))
  subtract_mseconds <- 0
  for(i in deks_to_fix){
    subtract_mseconds <- subtract_mseconds + 60000
    while((subtract_mseconds %in% rev$did) || 
     (subtract_mseconds %in% rev$id) || 
     (subtract_mseconds %in% rev$cid)) subtract_mseconds<-subtract_mseconds+1
    rev[rev$dek.nam==i,]$did <- first_time_used_anki - subtract_mseconds
    crd[crd$dek.nam==i,]$did <- first_time_used_anki - subtract_mseconds
  }
}
}
```

```{r updat in_rev in crd}
crd$in_rev <- (crd$cid) %in% rev$cid
```

Review id timestamps after trimming

```{r review id timestamps after trimming}
{
rev <- rev[order(rev$id),]
print(paste("when was first review:",milli_to_date(min(rev$id,na.rm=T))))
print(paste("when was last review:",milli_to_date(max(rev$id,na.rm=T)))) 
print(paste("which rev ids na:",which(is.na(rev$id))))
print(paste("which rev ids are duplicated:",which(duplicated(rev$id))))
print(paste("dimensions of review and card decks ", paste(c(dim(rev),dim(crd)),collapse = " ")))
print(paste("different cards ever reviewd", length(unique(rev$cid))))
print(paste("different notes ever reviewd", length(unique(rev$nid))))

}
```

```{r check after crit clean}
#Review table grouped by card.txt.old. End user need not bother with it.
if(F){
revie.deck.mis <- rev %>%  
  group_by(card.txt.old) %>%
   summarise(deck.name = first(dek.nam),
             revs.before.deck = sum(did>id),
             revstotal = n(),
             first.rview = first(id),
             deck.date = first(did)) %>%
  group_by(deck.name) %>%
   summarise(cardstotal=n(),
            cards.ever.before.deck = sum(revs.before.deck > 1), 
            revs.total = sum(revstotal), 
            revs.before.deck= sum(revs.before.deck),
             first.review=milli_to_date(first(first.rview)),
             deck.date=milli_to_date(first(deck.date))) %>%
  mutate(percent.new=revs.before.deck / revs.total) 

print(revie.deck.mis[order(revie.deck.mis$first.review),])
#summary(rev)
#str(rev)
}
```

## HEIRARCHY AND ACCUMULATION OF COLLECTION

```{r new plot of cards each month}
{
reviews.after.clean <- milli_to_date(rev$id)
hist(reviews.after.clean, breaks = 60)
# cards$created_date <- as.yearmon(anydate((cards$cid)/1000))
# cards_summary <- sqldf("select created_date, count(*) as n_cards from cards group by created_date order by created_date")
percent_unseen <- round(digits=3,sum((crd$nid) %in% rev$nid)/length((crd$nid)))
print(paste("percent notes actualy ever tried",percent_unseen
))
print(paste("calculated as ",
            sum((crd$nid) %in% rev$nid),
                                 '/',length((crd$nid))
))
if(percent_unseen<.5) print("looks like user has been making too many plans")

if(T){
rev <- rev[order(rev$id),]
rev$first.rev.of.a.note<-(!duplicated(rev$nid))

reved <- rev %>%
  group_by(nid) %>%
  summarise(min=min(id)) %>%
  arrange(min) %>% ungroup()
print(paste("number of reviews before notes", sum(reved$nid >= reved$min)))

#print(paste("both calculation methods agree",length(reved$min)==length(rev$id[rev$first.rev.of.a.note])))
}
}
```

```{r accumulation of cards in time}
rev<-rev[order(rev$id),]
crd<-crd[order(crd$did),]

nts_fg <- crd$did[!duplicated(crd$nid)]
nts_gd <- (crd$did[!duplicated(crd$nid) & (crd$in_rev)])

ggplot()+
  geom_histogram(aes(x=milli_to_date(rev$id),color=!rev$first.rev.of.a.note),binwidth = 60)+
  geom_point(aes(x=milli_to_date(nts_fg),cumsum(rep(1,times=length(nts_fg))),
                 color="cum notes in collection"))+
  geom_point(aes(x=milli_to_date(nts_gd),cumsum(rep(1,times=length(nts_gd))),
                 color="cn in coll, actualy used"))+
  geom_point(aes(x=milli_to_date(rev$id[rev$first.rev.of.a.note]),
                 cumsum(rep(1,times=length(rev$id[rev$first.rev.of.a.note]))),
                 color="cum notes seen"))+
  xlab("Date") + ylab("Histogram is of reviews of old and new cards")+ 
  ggtitle( "Points as cumulative sum of notes")+
  scale_x_date(date_breaks="6 months")+ 
  theme( axis.text.x = element_text(angle=30) )+
  labs(colour = " ")

ggplot()+
  geom_histogram(aes(x=milli_to_date(rev$id),color=!rev$first.rev.of.a.note),binwidth = 60)+
  geom_point(aes(x=milli_to_date(nts_gd),cumsum(rep(1,times=length(nts_gd))),
                 color="cn in coll, actualy used"))+
  geom_point(aes(x=milli_to_date(rev$id[rev$first.rev.of.a.note]),
                 cumsum(rep(1,times=length(rev$id[rev$first.rev.of.a.note]))),
                 color="cum notes seen"))+
  xlab("Date") + ylab("Histogram is of reviews of old and new cards")+ 
  ggtitle( "Points as cumulative sum of notes")+
  scale_x_date(date_breaks="6 months")+ 
  theme( axis.text.x = element_text(angle=30) )+
  labs(colour = " ")

```

The TRUE is reviews of cards already reviewed and FALSE is reviews of
new notes. A two sided note will make 2 cards like hand -\> mano and
mano -\> hand. Anki already has similar plot.

When were cards added that have ever been reviewed? Good and bad
decisions? INTERESTING

```{r good decisions when adding decks}
qdf <- data.frame(dion = c(nts_fg, nts_gd),
                  seen=c(rep(F,times=length(nts_fg)),rep(T,times=length(nts_gd))))

ggplot(data=qdf)+
  geom_histogram(aes(x=milli_to_date(dion),fill= seen),binwidth = 60)+
  scale_x_date(date_breaks="6 months")+ 
  theme( axis.text.x = element_text(angle=30) )+
  xlab("Date")+ 
  ggtitle( "When were notes added that were ever reviewed")

```

SELF REVIEW In first 2 months additions were well considered enough
but then got obsessed with additions. Somewhere around 2021-10 this
stopped and additions became better planned again.

```{r count cards in deck; simple deck name; add var to rev}

crd$simplest.name <- apply(crd, 1, function(x){
  levs<-str_split(x[names(x)=="dek.nam"],stringr::fixed(" -- "))[[1]]
  return(levs[length(levs)])
} )


rev$simplest.name <- apply(rev, 1, function(x){
  levs<-str_split(x[names(x)=="dek.nam"],stringr::fixed(" -- "))[[1]]
  return(levs[length(levs)])
} )

opp <- crd %>%  
  group_by(simplest.name) %>% 
  summarise(Cards_in_deck = n()) 

#stopifnot("final names of decks in reviews not in deck data.frame" = all(rev$simplest.name %in% opp$simplest.name))

any.odd.changes <- dim(rev) 

rev <- merge(rev,opp,all.x = T,all.y=F , by ="simplest.name")

stopifnot("number rows changed after merge" = dim(rev)[1]==any.odd.changes[1],
  "number columns changed after merge" = (dim(rev)[2])==(any.odd.changes[2]+1))

```

```{r decks by card count and usage}
#require(treemapify)
require(treemap, quietly = T)
require(grDevices, quietly = T)
 
opp <- crd %>%  
  group_by(simplest.name) %>% 
  summarise(
            Cards_in_deck = n(), 
            did = first(did),
            seen.once = sum((cid) %in% rev$cid)
  ) %>%
  mutate(
    percent_reviewed = (seen.once / Cards_in_deck),
    Sqrt.cards.in.deck = sqrt(Cards_in_deck),
    sqrt.cards.seen.once = sqrt(seen.once)
  )

#dim(opp)
#summary(opp)

treemap(opp, index="simplest.name", vSize="Cards_in_deck", vColor="percent_reviewed", type="manual", palette="RdYlBu")
 # itreemap(opp)
  
  treemap(opp, index="simplest.name", vSize="sqrt.cards.seen.once", vColor="percent_reviewed", type="manual", palette="RdYlBu")

```

TODO animate over time events of great addition?

Separate folder path into each folder name. First rev then crd. Check
if one folder name appears in another hierarchy level. Up to user to
fix.

```{r separate tree}
dek_name_to_heir <- function(var.to.split){
split_str <- str_split(var.to.split,stringr::fixed(" -- "))
pre_padded_df <- sapply(split_str, simplify="matrix",function(x){
  for(i in 1:(20-length(x))) x<-c(x,"")
return(x)
}) 
dek_heir_padded <- as.data.frame(t(pre_padded_df))
levels_not_empty <- (apply(dek_heir_padded, 2, 
                           function(x) length(unique(x)))!=1)
dek_heir_padded <- dek_heir_padded[,levels_not_empty]
max_lv <<- dim(dek_heir_padded)[2]
for(i in (max_lv):1) names(dek_heir_padded)[i] <- paste0("dek.heir.lev.",i)
return(dek_heir_padded)
}
dek_heir_unfurled <- dek_name_to_heir(rev$dek.nam)
#print(dek_heir_unfurled)
rev <- cbind(rev,dek_heir_unfurled)

for(itr in 1:(max_lv-1)){#itr<-1
  for(i in (max_lv-itr):1){#i<-1
    wish <- (unique(rev[,paste0("dek.heir.lev.",i)]) %in%                 unique(rev[,paste0("dek.heir.lev.",i+itr)]))
  #print(wish)
    itsy<-unique(rev[,paste0("dek.heir.lev.",i)])[wish]
    if(length(itsy)>0) if(any(nchar(itsy)>0)) print(paste("duplicate deck names ",itsy))
  }}

dek_heir_unfurled <- dek_name_to_heir(crd$dek.nam)
print(head(dek_heir_unfurled))
print(tail(dek_heir_unfurled))
crd <- cbind(crd,dek_heir_unfurled)


```

```{r check for dupli names}
for(itr in 1:(max_lv-1)){#itr<-1
  for(i in (max_lv-itr):1){#i<-1
    wish <- (unique(crd[,paste0("dek.heir.lev.",i)]) %in%                 unique(crd[,paste0("dek.heir.lev.",i+itr)]))
  #print(wish)
    itsy<-unique(crd[,paste0("dek.heir.lev.",i)])[wish]
    if(length(itsy)>0) {
      if(any(nchar(itsy)>0)){
      print(print(paste("duplicate deck names ",itsy)))
    }}
  }}

```

```{r deck folder heirarchy}
{
dx <- c("dek.heir.lev.1"  ,   
 "dek.heir.lev.2"   ,   "dek.heir.lev.3" ,    
 "dek.heir.lev.4"   ,   "dek.heir.lev.5" ,    "dek.heir.lev.6")
revgrp <- rev[,c(dx)]
#names(rev)
revgrp <- revgrp[!duplicated(revgrp),]
lvone <- unique(revgrp[,(1)])
edges <- data.frame(from=rep("root",length(lvone)),to=lvone)
edges <- data.frame(from=c(),to=c())
for(i in 2:dim(revgrp)[2]){ #i<-2
  hold <- data.frame(from= revgrp[,(i-1)], to= revgrp[,(i)])
  edges <- rbind(edges,hold)
}

set.seed(1234)
#names(edges)
edges <- edges[edges$to!="",]
nodes <- data.frame(node_key =unique(unlist(edges)))
g <- tbl_graph(edges=edges, directed=TRUE, nodes=nodes)
yout <- create_layout(g, layout = 'igraph', algorithm = 'fr' )
ggraph(g,layout=yout) + 
  geom_edge_link(alpha=.2) + 
  geom_node_point(size=2,color="red") +
  geom_node_text(aes(label = node_key),
                 repel=T,size=2)#angle=10,

#require(reactable)
#?reactable
}
```

Plot of deck folder hierarchy above. Deck must have at least one review to appear here.

Folders with cards as well as decks. Maybe make the bellow mentioned
decks not hold both cards and decks by moving the decks? (if move
cards may cause problems!)

```{r any folders with cards as well as decks?}
#um find every unique full deck name then check if it is part of any others and then that full deck name will be one with 
dek.evey <- sort(unique(crd$dek.nam))
logh <- str_split(dek.evey,stringr::fixed(" -- "))

nonlastset<-c()
for(i in 1:4){
huh<-lapply(logh,function(x){ #x<-logh[[6]]
  (try(silent = T,{x <- x[1:(length(x)-i)]
  return(
    paste(x,collapse = " -- ")
  )
  }))
  return("")
})
nonlastset<-unique(c(nonlastset,unlist(huh)))
}
crd$notendfolder <- crd$dek.nam %in% nonlastset
crd %>% filter(notendfolder) %>% group_by(dek.nam) %>% summarise(count= n())
 
```
not absolutely necessary but maybe good idea to fix (move cards, rename deck, create new heirarchy fork)

Check that duplicate columns in crd and rev have not diverged.

```{r check crd and rev redundancies are identical}
{
  names(crd)[names(crd)=="type"] <- "type_card"
  names(crd)[names(crd)=="ivl"] <- "ivl_card"
  names(crd)[names(crd)=="factor"] <- "factor_card"
  
cols <- names(crd)[names(crd) %in% names(rev)]
#print(cols)
tocompare <- rev[!duplicated(rev$cid),cols]
tocompare <- tocompare[order(tocompare$cid),]
crd_compare <- crd[order(crd$cid),cols]
crd_compare <- crd_compare[(crd_compare$cid) %in% tocompare$cid,]


if(nchar(all_equal(crd_compare,tocompare))>10){
  require(arsenal, quietly = T)
  require(diffdf, quietly = T)
  print("redundancies between rev and crd are not aligned this may be a big bug")
  dim(tocompare)
dim(crd_compare)
  #(all_equal(crd_compare,tocompare)[1:20])

print(diffdf(crd_compare,tocompare))

comparedf(crd_compare,tocompare)
}
}
```

## Templates to know what user sees before and after answering

Clean and join several tables into templates. notetypes & fields

```{r templates cleaned}

names(notetypes)[names(notetypes)=="config"] <- "prettynotes"
notetypes$prettynotes<-NULL #because raw-to-char can not deal with it
names(notetypes)[names(notetypes)=="name"] <- "notetypename"

names(templates)[names(templates)=="name"] <- "template_name"
names(templates)[names(templates)=="config"] <- "template_config"
names(templates)[names(templates)=="ord"] <- "template_ord"


```

```{r templates notetypes merged in}
stopifnot(
  all(sort(unique(fields$ntid))==sort(unique(fields$ntid))),
          all(notetypes$id %in% templates$ntid),
          all(templates$ntid %in% notetypes$id)
)
a <- dim(templates)
names(notetypes)
 templates <- merge(templates,notetypes,all=T,by.x = "ntid",by.y="id")#just adds one colum; notetype name
stopifnot(
  dim(templates)[1]==a[1],
  dim(templates)[2]==(a[2] + 1)
)
names(templates)

#summary(templates$ntid)

```

```{r templates & fields config blob into text}

typ<-c()
for(i in templates$template_config) try({typ<-c(typ,(rawToChar(unlist(unlist(i)))))})
templates$template_config <- typ

templates$template_config_recode <- stringi::stri_enc_toutf8(templates$template_config,is_unknown_8bit=TRUE,validate=T)

typ<-c()
for(i in fields$config){
  p=F
  try({
    typ<-c(typ,(rawToChar(unlist(unlist(i)))));
  p=T
  })
  if(!p) typ<-c(typ,"")
} 
fields$config <- typ
#fields$config <- NULL
names(fields)[names(fields)=="config"] <- "config_fields"
#print(sort(unique(fields$config_fields)))

templates$template_nchar <- nchar((templates$template_config_recode))
templates$is_cloze <- 0 < (str_detect(templates$template_config ,fixed("{cloze")) + str_detect(templates$template_config ,fixed("{{c1")))
summary(templates$is_cloze)

print("above the count of cloze deletion note types
      is it really ok to just fill in fields that failed to be parsed as _ 
      field config does not seeem to matter,
      template_config rawtochar is better than stringi stri_enc_toutf8")
diff_check=data.frame(((templates$template_config)),
((templates$template_config_recode)))
diff_check$identical <- diff_check[,1]== diff_check[,2]

# print(
#   diff_check[!diff_check$identical,]
# )
```

```{r templates, fields file aggregated & merged in}

stopifnot(all(sort(unique(fields$ntid))==sort(unique(fields$ntid))),
          all(templates$ntid %in% fields$ntid),
          all(fields$ntid %in% templates$ntid)
)

to_template <- fields %>%
  group_by(ntid) %>%
  summarize(
    max.ord.fields=max(ord),
    field_names = paste(name,sep = " -- ", collapse = " -- ")
  ) %>%
  ungroup()

a <- dim(templates)
#dim(to_template)
templates <- merge(templates,to_template,all=T,by.x = "ntid",by.y="ntid")
#adds max ord of fields (count of fields) and the field names
#later the ordered field names will be used with templates to make Q and A parts of each card
stopifnot(
  dim(templates)[1]==a[1],
  dim(templates)[2]==(a[2] + 2)
)  
templates$ntid <- as.numeric(templates$ntid)
names(templates)
```

Anki does not correctly describe what will and wont be part of front
and back of cards. sometimes no back so front is reused as back. sometimes
split more than once though in the one case I have seen there
is no real second back side just a symbol.

```{r template config html split between front and after answer}
tsl<-str_split(templates$template_config,pattern=fixed("\022"))

templates$template_config_front <- sapply(tsl, function(x) {
  x[1]
})

templates$template_config_back  <- sapply(tsl, function(x) {
  if(length(x)<2) return(x[1])
  if(length(x)==2) return(x[2])
  return(paste(x[2:3],collapse=""))
})

#tsl[[176]]
#templates$template_config_back[176]
```


```{r extract fields from template config html}
require(stringr)

#same as below but for entire html rather than split
# templates$fields_extracted <-
# str_extract_all(templates$template_config,pattern=regex("(?<=\\{{1,2}).*?(?=\\})")) 
# templates$fields_extracted <-
# apply(templates,1,function(x){
#   nup <- unlist(x$fields_extracted)
#   str_remove_all(nup,fixed("{"))
# }  )

templates$fields_front_extracted <-
str_extract_all(templates$template_config_front,pattern=regex("(?<=\\{{2}).*?(?=\\})")) 
templates$fields_front_extracted <-
apply(templates,1,function(x){
  nup <- unlist(x$fields_front_extracted)
  str_remove_all(nup,fixed("{"))
}  )

templates$fields_back_extracted <-
str_extract_all(templates$template_config_back,pattern=regex("(?<=\\{{2}).*?(?=\\})")) 
templates$fields_back_extracted <-
apply(templates,1,function(x){
  nup <- unlist(x$fields_back_extracted)
  str_remove_all(nup,fixed("{"))
}  )
```
Which fields are missing from back - answer side of card but are available on front
```{r is back ever missing info from front?}
#any(str_detect(templates$fields_back_extracted[[2]],fixed("FrontSide")))
templates$missing_front <- sapply(templates$fields_back_extracted , function(x) {
  !any(str_detect(x,fixed("FrontSide")))
})

# x<-templates[6,]
# a<-unlist(x$fields_front_extracted)
# b<-unlist(x$fields_back_extracted)
templates$missing_front <- apply(templates,1,simplify = T,function(x){
  if(!x$missing_front) return(F)
  a<-(x$fields_front_extracted)
  b<-x$fields_back_extracted
  front_fields_found<-str_detect(list(b),pattern=(a))
  front_fields_found<-pmax(front_fields_found,a %in% b)>0
  if(all(front_fields_found)) return(F)
  return(a[!front_fields_found])
})

templates$missing_front_count<-unlist(lapply(templates$missing_front, length))
templates$missing_front_count[templates$missing_front=="FALSE"]<-0

#View(templates[order((templates$missing_front_count)),])

#see all the unmatched field names
if(F){ 
tre<-templates$missing_front_count>0
apply(templates[tre,],1,function(x){
print(x$notetypename)
print(x$missing_front)
print("                            ")
print(x$fields_front_extracted)
print(x$fields_back_extracted)
print("------------------------------")
})
}
summary(templates$missing_front_count)
```

not all formal fields are in template config html and some are missed. this section catalogs those
```{r which Fields not in html}
templates$field_names_unmatched <- apply(templates,1,simplify = T,function(x){
  a<-unlist(str_split(x$field_names,pattern= " -- "))
  b<-c(x$fields_back_extracted,x$fields_front_extracted)
  #print(a)
  #print(b)
  field_names_found<-str_detect(list(b),pattern=(a))
  field_names_found<-pmax(field_names_found,a %in% b)>0
  if(all(field_names_found)) return(F)
  return(a[!field_names_found])
})

templates$field_names_unmatched_count<-unlist(lapply(templates$field_names_unmatched, length))
templates$field_names_unmatched_count[templates$field_names_unmatched=="FALSE"]<-0

#View(templates[order((templates$field_names_unmatched_count)),])

#see all the unmatched field names
if(F){ 
tre<-templates$field_names_unmatched_count>0
apply(templates[tre,],1,function(x){
print(x$notetypename)
print(x$field_names_unmatched)
print("                            ")
print(x$fields_front_extracted)
print(x$fields_back_extracted)
print("------------------------------")
})
}
summary(templates$field_names_unmatched_count)
```



## Remove most objects from memory and save the rest into files.


```{r delete remove objects for cleanliness}
saveRDS(rev,"rev.RDS")
saveRDS(crd,"crd.RDS")
saveRDS(templates,"templates.RDS")
if(T){
#rm(cards)
#rm(note)
#rm(crd)
#rm(dek)

rm(list=unlist(setdiff(ls(),c("rev","crd","templates"))))
}
gc()
save.image(file = 'Step_1_after.RData')
```
